# ARK AI Lab Configuration
# AI-focused deployment without media services
#
# Usage:
#   cp examples/.env.ai-lab .env
#   source .env
#   ./scripts/ark-manager.sh deploy

# Docker Compose Profiles
# Deploy core infrastructure and applications (no media)
COMPOSE_PROFILES=core,apps

# Optional: Override default paths if needed
# ARK_DIR=/opt/ark
# LOG_DIR=/opt/ark/logs

# Optional: Tailscale Auth Key (if not set in vessel_secrets.env)
# TAILSCALE_AUTHKEY=

# Optional: Code Server Password (if not set in vessel_secrets.env)
# CODE_SERVER_PASSWORD=arknode123
# CODE_SERVER_SUDO_PASSWORD=arknode123

# Resource Requirements:
# - RAM: ~8GB+ (12GB+ if running large AI models)
# - Storage: ~50GB+ (for AI models)
# - CPU: 4+ cores (GPU recommended for Ollama)
#
# Services Included:
# Core:
#   - Traefik, Tailscale, Autoheal, Homepage, Portainer, Syncthing
# Apps:
#   - Ollama (local LLM API)
#   - Open WebUI (AI chat interface)
#   - Kiwix (offline Wikipedia)
#   - Gitea (Git hosting)
#   - Code-Server (VS Code in browser)
#   - Vaultwarden (password manager)
#   - FileBrowser (file manager)
#
# Note: Media services (Jellyfin, Audiobookshelf, Home Assistant) are excluded
# to save resources for AI workloads.
